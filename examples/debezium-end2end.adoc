Env:

- AMQ Streams 2.5.0
- Debezium 2.4.0.Final
- MySQL 8.0

Prerequisties:

-  Install the AMQ Streams Operator from OperatorHub
-  Install the camelk Operator from OperatorHub

1. Create namespaces myproject, myproject2 and myproject3
2. Created the following Kafka clusters

[source, yaml,indent=0]
----
    oc create -f - <<EOF
    apiVersion: kafka.strimzi.io/v1beta2
    kind: Kafka
    metadata:
      name: my-cluster
    spec:
      kafka:
        config:
          offsets.topic.replication.factor: 1
          transaction.state.log.replication.factor: 1
          transaction.state.log.min.isr: 2
          default.replication.factor: 1
          min.insync.replicas: 1
          inter.broker.protocol.version: '3.5'
        storage:
          type: jbod
          volumes:
            - deleteClaim: false
              id: 0
              size: 1Gi
              type: persistent-claim
        listeners:
          - name: plain
            port: 9092
            type: internal
            tls: false
          - name: tls
            port: 9093
            type: internal
            tls: true
        version: 3.5.0
        replicas: 3
      entityOperator:
        topicOperator: {}
        userOperator: {}
      zookeeper:
        storage:
          deleteClaim: false
          size: 1Gi
          type: persistent-claim
        replicas: 3
    EOF
----
    
- Install Kafka connect CR with Debezium plugins through AMQ Streams:
- Building and Deploying Debezium Connectors:
- Create a KafkaConnect CR specifying connector plugins and other components.

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
  name: debezium-connect
  annotations:
    strimzi.io/use-connector-resources: "true"
spec:
  bootstrapServers: 'my-cluster-kafka-bootstrap:9093'
  build:
    output:
      image: >-
        image-registry.openshift-image-registry.svc:5000/dbz-mysql/dbz-mysql-connect:latest
      type: docker
    plugins:
      - artifacts:
          - type: tgz
            url: >-
              https://repo1.maven.org/maven2/io/debezium/debezium-connector-mongodb/2.4.0.Final/debezium-connector-mongodb-2.4.0.Final-plugin.tar.gz
        name: debezium-mongodb-connector
      - artifacts:
          - type: tgz
            url: >-
              https://repo1.maven.org/maven2/io/debezium/debezium-connector-postgres/2.4.0.Final/debezium-connector-postgres-2.4.0.Final-plugin.tar.gz
        name: debezium-postgres-connector
      - artifacts:
          - type: tgz
            url: >-
              https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/2.4.0.Final/debezium-connector-mysql-2.4.0.Final-plugin.tar.gz
        name: debezium-mysql-connector
  config:
    config.storage.replication.factor: -1
    config.storage.topic: dbz-mysql-connect-configs
    group.id: connect-cluster
    offset.storage.replication.factor: -1
    offset.storage.topic: dbz-mysql-connect-offsets
    status.storage.replication.factor: -1
    status.storage.topic: dbz-mysql-connect-status
  replicas: 1
  tls:
    trustedCertificates:
      - certificate: ca.crt
        secretName: my-cluster-cluster-ca-cert
  version: 3.5.0
EOF
----

## Check

[source, yaml,indent=0]
----
oc get kc debezium-connect -o yaml | yq '.status.connectorPlugins'
----

3. Deploy pre-populated MySQL instance

## Configure credentials for the database:

[source, yaml,indent=0]
----
oc new-app \
    -e MYSQL_ROOT_PASSWORD=debezium \
    -e MYSQL_USER=mysqluser \
    -e MYSQL_PASSWORD=mysqlpw \
    -e MYSQL_DATABASE=inventory \
    mysql:8.0-el9
----

[source, yaml,indent=0]
----
oc rsh `oc get pods -l deployment=mysql -o name` mysql -u mysqluser -pmysqlpw inventory

CREATE TABLE products
(
    id INT PRIMARY KEY NOT NULL,
    name VARCHAR(100),
    model VARCHAR(100),
    price INT
);


INSERT INTO products VALUES (1, 'LenovoT41', 'Lenovo T 41', 3);
INSERT INTO products VALUES (2, 'LenovoT41', 'Lenovo UT 41', 45);
INSERT INTO products VALUES (3, 'DELL', 'DELL 41', 45);
----

## kafka Connect CR - Build - SQL Instances:
## Kafka connect CR ######


## kafka Connector CR:
### Create KC with MYSQL Connector:

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  labels:
    strimzi.io/cluster: debezium-connect
  name: mysql-connector
spec:
  class: io.debezium.connector.mysql.MySqlConnector
  tasksMax: 1
  autoRestart:
    enabled: true
  config:
    database.hostname: mysql
    database.port: 3306
    database.user: root
    database.password: debezium
    database.server.id: 184057
    database.whitelist: inventory
    database.names: inventory
    include.schema.changes: false
    schema.history.internal.kafka.topic: schemahistory.fullfillment
    schema.history.internal.kafka.bootstrap.servers: 'my-cluster-kafka-bootstrap:9092'
    topic.prefix: mysql
    topic.creation.default.replication.factor: 1
    topic.creation.default.partitions: 1
EOF
----

## Check Status:

[source, yaml,indent=0]
----
$ oc get kctr
NAME              CLUSTER             CONNECTOR CLASS                              MAX TASKS   READY
mysql-connector   dbz-mysql-connect   io.debezium.connector.mysql.MySqlConnector   1           True
----

[source, yaml,indent=0]
----
oc get kctr mysql-connector -o yaml | yq '.status'

status:
  conditions:
  - lastTransitionTime: "2023-10-24T12:12:59.267139132Z"
    status: "True"
    type: Ready
  connectorStatus:
    connector:
      state: RUNNING
      worker_id: 10.131.0.22:8083
    name: mysql-connector
    tasks:
    - id: 0
      state: RUNNING
      worker_id: 10.131.0.22:8083
    type: source
  observedGeneration: 1
  tasksMax: 1
  topics:
  - mysql.inventory.products
----

- Remove Schema 

[source, yaml,indent=0]
----
oc patch kctr mysql-connector-p '{"spec": {"config": {"key.converter": org.apache.kafka.connect.json.JsonConverter,"key.converter.schemas.enable": false,"value.converter": org.apache.kafka.connect.json.JsonConverter, "value.converter.schemas.enable": false}}}'
----


- Remove Header

[source, yaml,indent=0]
----
oc patch kctr mysql-connector-p '{"spec": {"config": {"transforms": unwrap,"transforms.unwrap.operation.header": true,"transforms.unwrap.drop.tombstones": false, "transforms.unwrap.type": io.debezium.transforms.ExtractNewRecordState}}}'
----

- Add signal configuration and trigger ad hoc snapshot:

#### Signal ;;;

[source, yaml,indent=0]
----
oc rsh `oc get pods -l deployment=mysql -o name` mysql -u mysqluser -pmysqlpw inventory
----

The following example shows a CREATE TABLE command that creates a three-column debezium_signal table:

[source, yaml,indent=0]
----
CREATE TABLE debezium_signal (id VARCHAR(42) PRIMARY KEY, type VARCHAR(32) NOT NULL, data VARCHAR(2048) NULL);

oc rsh `oc get pods -l deployment=mysql -o name` mysql -u mysqluser -pmysqlpw inventory

CREATE TABLE customers (
  id SERIAL,
  first_name VARCHAR(255) NOT NULL,
  last_name VARCHAR(255) NOT NULL,
  email VARCHAR(255) NOT NULL,
  PRIMARY KEY(id)
);


INSERT INTO customers VALUES (1, 'Test1', 'TEST1', 'test@test.com');
INSERT INTO customers VALUES (2, 'Test2', 'TEST2', 'test@test.com');
INSERT INTO customers VALUES (3, 'Test2', 'TEST3', 'test@test.com');
----

- Add to kafka Connector CR:

    signal.kafka.topic: mysql.debezium_signal
    signal.kafka.bootstrap.servers: 'my-cluster-kafka-bootstrap:9092'
    signal.enabled.channels: 'source,kafka,jmx'
    signal.data.collection: inventory.debezium_signal

LOGS:

[source, yaml,indent=0]
----
dbz-mysql-connect-connect-746b688cbb-p2xvf dbz-mysql-connect-connect 2023-10-25 08:23:03,638 WARN [mysql-connector|task-0] [Consumer clientId=e79dab95-01b5-41d2-ad70-4662e56fa6a6, groupId=kafka-signal] Error while fetching metadata with correlation id 1 : {mysql.debezium_signal=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient) [debezium-mysqlconnector-mysql-SignalProcessor]
dbz-mysql-connect-connect-746b688cbb-p2xvf dbz-mysql-connect-connect 2023-10-25 08:23:03,638 INFO [mysql-connector|task-0] [Consumer clientId=e79dab95-01b5-41d2-ad70-4662e56fa6a6, groupId=kafka-signal] Cluster ID: DO1r2ddtQNKzZwOKSJnGhg (org.apache.kafka.clients.Metadata) [debezium-mysqlconnector-mysql-SignalProcessor]
dbz-mysql-connect-connect-746b688cbb-p2xvf dbz-mysql-connect-connect 2023-10-25 08:23:03,640 INFO [mysql-connector|task-0] [Consumer clientId=e79dab95-01b5-41d2-ad70-4662e56fa6a6, groupId=kafka-signal] Discovered group coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.dbz-mysql.svc:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator) [debezium-mysqlconnector-mysql-SignalProcessor]
dbz-mysql-connect-connect-746b688cbb-p2xvf dbz-mysql-connect-connect 2023-10-25 08:23:03,645 INFO [mysql-connector|task-0] [Consumer clientId=e79dab95-01b5-41d2-ad70-4662e56fa6a6, groupId=kafka-signal] Found no committed offset for partition mysql.debezium_signal-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator) [debezium-mysqlconnector-mysql-SignalProcessor]
----

## Trigger Snapshot:

[source, yaml,indent=0]
----
#!/usr/bin/env bash
STRIMZI_IMAGE="registry.redhat.io/amq7/amq-streams-kafka-32-rhel8:2.2.0"
krun() { kubectl run krun-"$(date +%s)" -it --rm --restart="Never" --image="$STRIMZI_IMAGE" -- "$@"; }

krun bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic mysql.debezium_signal --property parse.key=true --property key.separator=:

mysql:{"type":"execute-snapshot","data": {"data-collections": ["inventory.customers"], "type": "INCREMENTAL"}}
----
